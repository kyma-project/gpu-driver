apiVersion: v1
kind: PersistentVolume
metadata:
  name: model-cache-pv
spec:
  capacity:
    storage: 1Ti
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  nfs:
    path: /main
    server: 10.102.230.250
    readOnly: false
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: model-cache-pvc
spec:
  storageClassName: ""
  volumeName: model-cache-pv
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Ti
---
apiVersion: v1
kind: Pod
metadata:
  name: image-generator-5
spec:
  containers:
    - name: image-generator
      image: ghcr.io/pbochynski/diffusers-k8s:0.0.5
      command:
        - "python3"
        - "generate_image.py"
        - "--device=cuda"
      ports:
        - containerPort: 8000
      volumeMounts:
        - name: storage
          mountPath: /root/.cache/huggingface
          subPath: r005/model-cache
        - name: storage
          mountPath: /app/output
          subPath: output
      resources:
        limits:
          nvidia.com/gpu: "1" # Ensure GPU is requested
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: model-cache-pvc
---
apiVersion: v1
kind: Pod
metadata:
  name: image-viewer
spec:
  containers:
    - name: image-generator
      image: ghcr.io/pbochynski/diffusers-k8s:0.0.5
      command:
        - "python3"
        - "-m"
        - "http.server"
        - "8000"
      ports:
        - containerPort: 8000
      volumeMounts:
        - name: storage
          mountPath: /app/storage
  volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: model-cache-pvc
